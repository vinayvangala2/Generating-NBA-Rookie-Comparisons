{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a6dc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://www.basketball-reference.com/leagues/NBA_2001_advanced.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▎                                                                               | 1/25 [00:06<02:44,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://www.basketball-reference.com/leagues/NBA_2002_advanced.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                            | 2/25 [00:12<02:25,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://www.basketball-reference.com/leagues/NBA_2003_advanced.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                            | 2/25 [00:16<03:04,  8.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 51\u001b[0m\n\u001b[0;32m     47\u001b[0m             all_avgs\u001b[38;5;241m.\u001b[39mappend(avg_df)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(all_players, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), pd\u001b[38;5;241m.\u001b[39mconcat(all_avgs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 51\u001b[0m player_df, league_avg_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_all_seasons\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2025\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m player_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnba_advanced_stats_2001_2025_players.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m league_avg_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnba_advanced_stats_2001_2025_league_averages.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m, in \u001b[0;36mscrape_all_seasons\u001b[1;34m(start, end)\u001b[0m\n\u001b[0;32m     40\u001b[0m all_avgs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(start, end \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m---> 43\u001b[0m     players_df, avg_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_season\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m players_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m         all_players\u001b[38;5;241m.\u001b[39mappend(players_df)\n",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m, in \u001b[0;36mscrape_season\u001b[1;34m(season_end_year)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError fetching \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m — Status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m extract_advanced_table(soup)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:335\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:478\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m--> 478\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:380\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    378\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;66;03m# html.parser raises AssertionError in rare cases to\u001b[39;00m\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# indicate a fatal problem with the markup, especially\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# when there's an error in the doctype declaration.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserRejectedMarkup(e)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\html\\parser.py:111\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\html\\parser.py:171\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m startswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m, i):\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m starttagopen\u001b[38;5;241m.\u001b[39mmatch(rawdata, i): \u001b[38;5;66;03m# < + letter\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m    173\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\html\\parser.py:303\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_starttag\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__starttag_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 303\u001b[0m     endpos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_for_whole_start_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m endpos \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m endpos\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\html\\parser.py:353\u001b[0m, in \u001b[0;36mHTMLParser.check_for_whole_start_tag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_for_whole_start_tag\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[1;32m--> 353\u001b[0m     rawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrawdata\u001b[49m\n\u001b[0;32m    354\u001b[0m     m \u001b[38;5;241m=\u001b[39m locatestarttagend_tolerant\u001b[38;5;241m.\u001b[39mmatch(rawdata, i)\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_advanced_table(soup):\n",
    "    table = soup.find(\"table\", {\"id\": \"advanced\"})\n",
    "    if table:\n",
    "        return pd.read_html(str(table))[0]\n",
    "    return None\n",
    "\n",
    "def scrape_season(season_end_year):\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season_end_year}_advanced.html\"\n",
    "    print(f\"Fetching {url}\")\n",
    "    res = requests.get(url)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error fetching {url} — Status code {res.status_code}\")\n",
    "        return None, None\n",
    "\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    df = extract_advanced_table(soup)\n",
    "    if df is None:\n",
    "        print(f\"Advanced stats table not found for {season_end_year}\")\n",
    "        return None, None\n",
    "\n",
    "    season_label = f\"{season_end_year - 1}-{str(season_end_year)[-2:]}\"\n",
    "    df[\"Season\"] = season_label\n",
    "\n",
    "    if \"Player\" in df.columns:\n",
    "        league_avg = df[df[\"Player\"] == \"League Average\"].copy()\n",
    "        players = df[df[\"Player\"] != \"League Average\"].copy()\n",
    "    else:\n",
    "        league_avg = pd.DataFrame()\n",
    "        players = df\n",
    "\n",
    "    return players, league_avg\n",
    "\n",
    "def scrape_all_seasons(start=2001, end=2025):\n",
    "    all_players = []\n",
    "    all_avgs = []\n",
    "\n",
    "    for year in tqdm(range(start, end + 1)):\n",
    "        players_df, avg_df = scrape_season(year)\n",
    "        if players_df is not None:\n",
    "            all_players.append(players_df)\n",
    "        if avg_df is not None and not avg_df.empty:\n",
    "            all_avgs.append(avg_df)\n",
    "\n",
    "    return pd.concat(all_players, ignore_index=True), pd.concat(all_avgs, ignore_index=True)\n",
    "\n",
    "player_df, league_avg_df = scrape_all_seasons(2001, 2025)\n",
    "player_df.to_csv(\"nba_advanced_stats_2001_2025_players.csv\", index=False)\n",
    "league_avg_df.to_csv(\"nba_advanced_stats_2001_2025_league_averages.csv\", index=False)\n",
    "print(\"Saved:\")\n",
    "print(\" - Player data → nba_advanced_stats_2001_2025_players.csv\")\n",
    "print(\" - League averages → nba_advanced_stats_2001_2025_league_averages.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e72f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rookie_table(soup):\n",
    "    table = soup.find(\"table\", {\"id\": \"rookies\"})\n",
    "    if table:\n",
    "        return pd.read_html(str(table))[0]\n",
    "    return None\n",
    "\n",
    "def scrape_rookie_season(season_end_year):\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season_end_year}_rookies.html\"\n",
    "    print(f\"Fetching {url}\")\n",
    "    res = requests.get(url)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"Error fetching {url} — Status code {res.status_code}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    df = extract_rookie_table(soup)\n",
    "    if df is not None:\n",
    "        df[\"Season\"] = f\"{season_end_year - 1}-{str(season_end_year)[-2:]}\"\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Rookie table not found for {season_end_year}\")\n",
    "        return None\n",
    "\n",
    "def scrape_all_rookie_seasons(start=2001, end=2025):\n",
    "    all_dfs = []\n",
    "    for year in tqdm(range(start, end + 1)):\n",
    "        df = scrape_rookie_season(year)\n",
    "        if df is not None:\n",
    "            all_dfs.append(df)\n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "df_all = scrape_all_rookie_seasons(2001, 2025)\n",
    "df_all.to_csv(\"nba_rookie_stats_2001_2025.csv\", index=False)\n",
    "print(\"Saved to nba_rookie_stats_2001_2025.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01891f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned file saved as nba_rookie_names_and_seasons.csv\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"nba_rookie_stats_2001_2025.csv\", header=None)\n",
    "\n",
    "df_raw.columns = df_raw.iloc[1]\n",
    "df = df_raw.iloc[2:].copy()\n",
    "\n",
    "df = df[(df[\"Rk\"] != \"Rk\") & (df[\"G\"] != \"Totals\")].copy()\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "df = df.rename(columns={last_col: \"Season\"})\n",
    "\n",
    "df_minimal = df[[\"Player\", \"Season\"]].copy()\n",
    "\n",
    "df_minimal.to_csv(\"nba_rookie_names_and_seasons.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned file saved as nba_rookie_names_and_seasons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c96efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
