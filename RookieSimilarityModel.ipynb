{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fc625ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned, filtered, and split data saved:\n",
      " - rookie_train_pre2023.csv\n",
      " - rookie_test_2023on.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"rookie_stats_final_clean.csv\")\n",
    "if \"BAR\" in df.columns:\n",
    "    df[\"BAR\"] = df[\"BAR\"].str.rstrip('%').astype(float)\n",
    "    \n",
    "df[\"SeasonStart\"] = df[\"Season\"].str.extract(r\"(\\d{4})\").astype(int)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "train_df = df[df[\"SeasonStart\"] <= 2022]\n",
    "test_df = df[df[\"SeasonStart\"] >= 2023]\n",
    "\n",
    "train_df.to_csv(\"rookie_train_pre2023.csv\", index=False)\n",
    "test_df.to_csv(\"rookie_test_2023on.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned, filtered, and split data saved:\")\n",
    "print(\" - rookie_train_pre2023.csv\")\n",
    "print(\" - rookie_test_2023on.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0deba7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 complete\n",
      "Epoch  1 complete\n",
      "Epoch  2 complete\n",
      "Epoch  3 complete\n",
      "Epoch  4 complete\n",
      "Epoch  5 complete\n",
      "Epoch  6 complete\n",
      "Epoch  7 complete\n",
      "Epoch  8 complete\n",
      "Epoch  9 complete\n",
      "Epoch  10 complete\n",
      "Epoch  11 complete\n",
      "Epoch  12 complete\n",
      "Epoch  13 complete\n",
      "Epoch  14 complete\n",
      "Epoch  15 complete\n",
      "Epoch  16 complete\n",
      "Epoch  17 complete\n",
      "Epoch  18 complete\n",
      "Epoch  19 complete\n",
      "Epoch  20 complete\n",
      "Epoch  21 complete\n",
      "Epoch  22 complete\n",
      "Epoch  23 complete\n",
      "Epoch  24 complete\n",
      "Epoch  25 complete\n",
      "Epoch  26 complete\n",
      "Epoch  27 complete\n",
      "Epoch  28 complete\n",
      "Epoch  29 complete\n",
      "Epoch  30 complete\n",
      "Epoch  31 complete\n",
      "Epoch  32 complete\n",
      "Epoch  33 complete\n",
      "Epoch  34 complete\n",
      "Epoch  35 complete\n",
      "Epoch  36 complete\n",
      "Epoch  37 complete\n",
      "Epoch  38 complete\n",
      "Epoch  39 complete\n",
      "Epoch  40 complete\n",
      "Epoch  41 complete\n",
      "Epoch  42 complete\n",
      "Epoch  43 complete\n",
      "Epoch  44 complete\n",
      "Epoch  45 complete\n",
      "Epoch  46 complete\n",
      "Epoch  47 complete\n",
      "Epoch  48 complete\n",
      "Epoch 50/200 - Loss: 0.095527\n",
      "Epoch  49 complete\n",
      "Epoch  50 complete\n",
      "Epoch  51 complete\n",
      "Epoch  52 complete\n",
      "Epoch  53 complete\n",
      "Epoch  54 complete\n",
      "Epoch  55 complete\n",
      "Epoch  56 complete\n",
      "Epoch  57 complete\n",
      "Epoch  58 complete\n",
      "Epoch  59 complete\n",
      "Epoch  60 complete\n",
      "Epoch  61 complete\n",
      "Epoch  62 complete\n",
      "Epoch  63 complete\n",
      "Epoch  64 complete\n",
      "Epoch  65 complete\n",
      "Epoch  66 complete\n",
      "Epoch  67 complete\n",
      "Epoch  68 complete\n",
      "Epoch  69 complete\n",
      "Epoch  70 complete\n",
      "Epoch  71 complete\n",
      "Epoch  72 complete\n",
      "Epoch  73 complete\n",
      "Epoch  74 complete\n",
      "Epoch  75 complete\n",
      "Epoch  76 complete\n",
      "Epoch  77 complete\n",
      "Epoch  78 complete\n",
      "Epoch  79 complete\n",
      "Epoch  80 complete\n",
      "Epoch  81 complete\n",
      "Epoch  82 complete\n",
      "Epoch  83 complete\n",
      "Epoch  84 complete\n",
      "Epoch  85 complete\n",
      "Epoch  86 complete\n",
      "Epoch  87 complete\n",
      "Epoch  88 complete\n",
      "Epoch  89 complete\n",
      "Epoch  90 complete\n",
      "Epoch  91 complete\n",
      "Epoch  92 complete\n",
      "Epoch  93 complete\n",
      "Epoch  94 complete\n",
      "Epoch  95 complete\n",
      "Epoch  96 complete\n",
      "Epoch  97 complete\n",
      "Epoch  98 complete\n",
      "Epoch 100/200 - Loss: 0.059480\n",
      "Epoch  99 complete\n",
      "Epoch  100 complete\n",
      "Epoch  101 complete\n",
      "Epoch  102 complete\n",
      "Epoch  103 complete\n",
      "Epoch  104 complete\n",
      "Epoch  105 complete\n",
      "Epoch  106 complete\n",
      "Epoch  107 complete\n",
      "Epoch  108 complete\n",
      "Epoch  109 complete\n",
      "Epoch  110 complete\n",
      "Epoch  111 complete\n",
      "Epoch  112 complete\n",
      "Epoch  113 complete\n",
      "Epoch  114 complete\n",
      "Epoch  115 complete\n",
      "Epoch  116 complete\n",
      "Epoch  117 complete\n",
      "Epoch  118 complete\n",
      "Epoch  119 complete\n",
      "Epoch  120 complete\n",
      "Epoch  121 complete\n",
      "Epoch  122 complete\n",
      "Epoch  123 complete\n",
      "Epoch  124 complete\n",
      "Epoch  125 complete\n",
      "Epoch  126 complete\n",
      "Epoch  127 complete\n",
      "Epoch  128 complete\n",
      "Epoch  129 complete\n",
      "Epoch  130 complete\n",
      "Epoch  131 complete\n",
      "Epoch  132 complete\n",
      "Epoch  133 complete\n",
      "Epoch  134 complete\n",
      "Epoch  135 complete\n",
      "Epoch  136 complete\n",
      "Epoch  137 complete\n",
      "Epoch  138 complete\n",
      "Epoch  139 complete\n",
      "Epoch  140 complete\n",
      "Epoch  141 complete\n",
      "Epoch  142 complete\n",
      "Epoch  143 complete\n",
      "Epoch  144 complete\n",
      "Epoch  145 complete\n",
      "Epoch  146 complete\n",
      "Epoch  147 complete\n",
      "Epoch  148 complete\n",
      "Epoch 150/200 - Loss: 0.046284\n",
      "Epoch  149 complete\n",
      "Epoch  150 complete\n",
      "Epoch  151 complete\n",
      "Epoch  152 complete\n",
      "Epoch  153 complete\n",
      "Epoch  154 complete\n",
      "Epoch  155 complete\n",
      "Epoch  156 complete\n",
      "Epoch  157 complete\n",
      "Epoch  158 complete\n",
      "Epoch  159 complete\n",
      "Epoch  160 complete\n",
      "Epoch  161 complete\n",
      "Epoch  162 complete\n",
      "Epoch  163 complete\n",
      "Epoch  164 complete\n",
      "Epoch  165 complete\n",
      "Epoch  166 complete\n",
      "Epoch  167 complete\n",
      "Epoch  168 complete\n",
      "Epoch  169 complete\n",
      "Epoch  170 complete\n",
      "Epoch  171 complete\n",
      "Epoch  172 complete\n",
      "Epoch  173 complete\n",
      "Epoch  174 complete\n",
      "Epoch  175 complete\n",
      "Epoch  176 complete\n",
      "Epoch  177 complete\n",
      "Epoch  178 complete\n",
      "Epoch  179 complete\n",
      "Epoch  180 complete\n",
      "Epoch  181 complete\n",
      "Epoch  182 complete\n",
      "Epoch  183 complete\n",
      "Epoch  184 complete\n",
      "Epoch  185 complete\n",
      "Epoch  186 complete\n",
      "Epoch  187 complete\n",
      "Epoch  188 complete\n",
      "Epoch  189 complete\n",
      "Epoch  190 complete\n",
      "Epoch  191 complete\n",
      "Epoch  192 complete\n",
      "Epoch  193 complete\n",
      "Epoch  194 complete\n",
      "Epoch  195 complete\n",
      "Epoch  196 complete\n",
      "Epoch  197 complete\n",
      "Epoch  198 complete\n",
      "Epoch 200/200 - Loss: 0.038965\n",
      "Epoch  199 complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "df = pd.read_csv(\"rookie_train_pre2023.csv\")\n",
    "\n",
    "player_names = df[\"Player\"].values\n",
    "\n",
    "features_df = df.drop(columns=[\"Player\", \"Season\", \"SeasonStart\"], errors=\"ignore\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features_df.astype(np.float32))\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim=8):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Linear(input_dim, 128),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, encoding_dim)\n",
    "    )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "        nn.Linear(encoding_dim, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, input_dim)\n",
    "    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "input_dim = X_tensor.shape[1]\n",
    "encoding_dim = 8\n",
    "model = Autoencoder(input_dim, encoding_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "epochs = 200\n",
    "i = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_tensor)\n",
    "    loss = loss_fn(output, X_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss.item():.6f}\")\n",
    "    print(\"Epoch \" ,  i , \"complete\")\n",
    "    i += 1\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    encoded_data = model.encoder(X_tensor).numpy()\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=6, metric=\"euclidean\")\n",
    "knn.fit(encoded_data)\n",
    "\n",
    "def find_similar(player_name, top_n=5):\n",
    "    if player_name not in player_names:\n",
    "        print(f\"Player '{player_name}' not found in training data.\")\n",
    "        return\n",
    "\n",
    "    idx = np.where(player_names == player_name)[0][0]\n",
    "    query_vec = encoded_data[idx].reshape(1, -1)\n",
    "    distances, indices = knn.kneighbors(query_vec, n_neighbors=top_n + 1)\n",
    "\n",
    "    print(f\"\\n Top {top_n} most similar rookies to {player_name}:\")\n",
    "    for rank, (i, dist) in enumerate(zip(indices[0][1:], distances[0][1:]), start=1):\n",
    "        print(f\"{rank}. {player_names[i]} (distance: {dist:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95055d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_post2023_player(player_name, test_csv=\"rookie_test_2023on.csv\", top_n=5):\n",
    "    test_df = pd.read_csv(test_csv)\n",
    "    test_df.dropna(inplace=True)\n",
    "\n",
    "    row = test_df[test_df[\"Player\"] == player_name]\n",
    "    if row.empty:\n",
    "        print(f\" Player '{player_name}' not found in {test_csv}\")\n",
    "        return\n",
    "\n",
    "    row_features = row.drop(columns=[\"Player\", \"Season\", \"SeasonStart\"], errors=\"ignore\")\n",
    "\n",
    "    row_scaled = scaler.transform(row_features.astype(np.float32))\n",
    "    row_tensor = torch.tensor(row_scaled, dtype=torch.float32)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        row_encoded = model.encoder(row_tensor).numpy()\n",
    "\n",
    "    distances, indices = knn.kneighbors(row_encoded, n_neighbors=top_n)\n",
    "\n",
    "    print(f\"\\n Top {top_n} similar rookies to {player_name}:\")\n",
    "    for rank, (j, dist) in enumerate(zip(indices[0], distances[0]), 1):\n",
    "        print(f\"{rank}. {player_names[j]} (distance: {dist:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc5379ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 5 similar rookies to Cody Williams:\n",
      "1. Joshua Primo (distance: 1.2044)\n",
      "2. Xavier Henry (distance: 1.4260)\n",
      "3. Bryce McGowens (distance: 1.5694)\n",
      "4. Antoine Wright (distance: 1.7309)\n",
      "5. Josh Hall (distance: 1.7946)\n"
     ]
    }
   ],
   "source": [
    "find_similar_post2023_player(\"Cody Williams\", top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873515ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
